# @package _global_
# module:
#   _target_: emg2qwerty.lightning.TDSConvCTCModule
#   in_features: 528  # freq * channels = (n_fft // 2 + 1) * 16
#   mlp_features: [384]
#   block_channels: [24, 24, 24, 24]
#   kernel_width: 32  # Total temporal receptive field of 125 samples given 4 layers


# module:
#   _target_: emg2qwerty.lightning.RNNCTCModule
#   in_features: 528  # freq * channels = (n_fft // 2 + 1) * 16
#   mlp_features: [384]
#   rnn_hidden_size: 128   
#   rnn_num_layers: 1 
#   rnn_type: RNN         # LSTM, GRU or RNN

module:
  _target_: emg2qwerty.lightning.TDSConvRNNCTCModule
  in_features: 528  # freq * channels = (n_fft // 2 + 1) * 16
  mlp_features: [384]
  block_channels: [24, 24, 24, 24]
  kernel_width: 32  # Total temporal receptive field of 125 samples given 4 layers
  rnn_hidden_size: 128   # 
  rnn_num_layers: 4      # 
  rnn_type: LSTM         # LSTM, GRU or RNN

# module:
#   _target_: emg2qwerty.lightning.RNNCTCModule
#   in_features: 528  # freq * channels = (n_fft // 2 + 1) * 16
#   mlp_features: [384]
#   rnn_hidden_size: 128   
#   rnn_num_layers: 4
#   rnn_type: RNN         # LSTM, GRU or RNN

# module:
#   _target_: emg2qwerty.lightning.TDSConvTransformerCTCModule

#   in_features: 528 
#   mlp_features: [384] 
#   block_channels: [24, 24, 24, 24]
#   kernel_width: 32           

#   transformer_d_model: 128 
#   transformer_nhead: 8  
#   transformer_num_layers: 4 

# module:
#   _target_: emg2qwerty.lightning.TransformerCTCModule
#   in_features: 528
#   mlp_features: [384]
#   transformer_d_model: 128
#   transformer_nhead: 8
#   transformer_num_layers: 4


datamodule:
  _target_: emg2qwerty.lightning.WindowedEMGDataModule
  window_length: 8000  # 4 sec windows for 2kHz EMG
  padding: [1800, 200]  # 900ms past context, 100ms future context
